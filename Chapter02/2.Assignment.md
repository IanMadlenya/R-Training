# Assignment 2 for R-Training Project

Mastery of the R Programming Language and general data-oriented problem solving technics requires in-depth understanding of the data structures and a rich experience of effectively and efficiently manipulating those building blocks.

## Vectors

1. Define several atomic vectors of different types and lengths, and use `object.size` function to investigate the number of bytes these vector objects take in memory. How does the object size of logical vector increase as the number of entries of a logical vector increases? How about numeric vectors? Why in your opinion do they behave differently? Refer to `The R language definition`, see how this depends on the architecture of the CPU (32-bit or 64-bit), and what the largest in-memory allocation is allowed for such vector types is?

2. Design an experiment to determine whether a numeric vector is copied in memory when its entries are modified (use `tracemem` function to trace a given object in memory). Does this happen to other atomic vector types? What's the implication for very large atomic vectors? How about lists? Can you figure out a method to determine whether the whole list or only the part that are being modified is copied when its members are mutated? Refer to 
`The R language definition` and describe the `copy on write` mechanism. What are the advantages and disadvantages of this language design?

3. What operations would one usually perform on logical vectors? What about numeric vectors and character vectors? What about lists? Give as many cases as you can where atomic vectors should be used instead of lists, where lists should be used instead of atomic vectors, and where both atomic vectors and lists can be used interchangeably. 

4. Coercion of atomic vectors is often implicitly done and thus causing unexpected results in type-sensitive operations. Try `as` functions such as `as.numeric` on objects of other vector types and use `storage.mode`, `mode`, and `class` to query the data type associated with the converted objects, and refer to `The R language definition` on the internal working of atomic vector types as evidenced by `storage.mode`, `mode`, and `class`. Then try `+` on different combinations of atomic vector types and see in what cases the  operation is valid and in what cases is not, and in the former cases what coercion is performed and whether it is always desirable.

5. Vectorization is computationally efficient and semantically elegant way of doing arithmetics. Perform `+` and `*` on two vectors of the same length by vectorization and by entry-wise iteration with `for` loop and use `system.time` to compare the computing time for each approach respectively. Similarly, try math functions such as `sin`, `log`, and furthermore, `pmax`, `pmin`, `ifelse`. In view of the advantages of vectorization, in what cases is vectorization not appropriate, and why?

6. Manipulation of vectors and lists can often be reduced to combination of several higher-order functions. The most basic ones are the `apply` family. Carefully differentiate between `apply`, `lapply`, `sapply`, `vapply`, `tapply`, `mapply`, `rapply`, and `eapply`. Also, try another family, the "Common Higher-Order Functions in Functional Programming Languages": `Reduce`, `Filter`, `Find`, `Map`, `Negate`, and `Position`. Furthermore, get to know the functions in `rlist` package. What's the benefit of using higher-order functions? Refer to wikipedia and contrast functional programming to other paradigms.

## Matrices and arrays

Do similar tasks in `Vector` section on matrices and arrays.

## Data frames

1. When is it more appropriate to use lists than data frames and when data frames than lists? 
 
2. Experiment the `copy on write` behavior of data frames and see it is more like the behavior of a list or of a matrix.

3. "Growing" an object is usually not an efficient way of dynamically storing data. Compare the computing time of growing a data frame row by row or column by column. Is there any significant difference in computing time in these two practices? Why or why not, in your opinion? Can you avoid growing a data frame by pre-allocating one of a size large enough? What do you do if the size actually needed cannot be known in advance? Is growing a list indeed less efficient than pre-allocating enough members?

4. Get to know the functionality and design principles of `plyr` and `dplyr`. Try examples provided in the packages and make conclusions on the commonality of the tasks, ease of use of the higher-order functions developed, and performance benchmarked by your own solution of similar tasks.

5. Get to know the functionality and design principles of `reshape2`. Try examples provided in the package and consider the working scenarios where `dcast` and `melt` can greatly simplify complex tasks.

6. Get familiar with `sqldf`. Try examples provided in the package and consider how tasks that cannot easily be reduced to utilizing former package functionalities can possibly be accomplished by harnessing the power of SQL on data frames.

7. Missing values could emerge from almost everywhere in real-world data analysis. Try the `na` family, such as `na.omit` in `stats` and `na.locf` in `zoo`, and determine which are the most useful ones in your working scenarios.
